---
title: "Equation"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Similarity

### Cosine similarity ("cosine")

$$
simil = \frac{\sum{\vec{x}\vec{y}}}{\sqrt{\sum{\vec{x} ^ 2}} \sqrt{\sum{\vec{y} ^ 2}}}
$$

### Pearson correlation coefficient ("correlation")

$$
simil = \frac{Cov(\vec{x},\vec{y})}{Var(\vec{x}) Var(\vec{y})}
$$

### Jaccard similarity ("jaccard" and "ejaccard")

The values of $x$ and $y$ are Boolean for "jaccard".

$$
e = \sum{\vec{x} \vec{y}} \\
w = \text{user-provided weight} \\
simil = \frac{e}{\sum{\vec{x} ^ w} + \sum{\vec{y} ^ w} - e}
$$

### Dice similarity ("dice" and "edice")

The values of $x$ and $y$ are Boolean for "dice".

$$
e = \sum{\vec{x} \vec{y}} \\
w = \text{user-provided weight} \\
simil = \frac{2 e}{\sum{\vec{x} ^ w} + \sum{\vec{y} ^ w}}
$$

### Hamann similarity ("hamann")


### Faith similarity ("faith")



### Simple matching ("matching")

$$
simil = \sum{\vec{x} = \vec{y}}
$$

## Distance

### Manhattan distance ("manhattan")

$$
dist = \sum{|\vec{x} - \vec{y}|}
$$

### Canberra distance ("canberra")

$$
dist = \frac{|\vec{x} - \vec{y}|}{|\vec{x}| + |\vec{y}|}
$$

### Euclidian ("euclidian")

$$
dist = \sum{\sqrt{\vec{x}^2 + \vec{y}^2}}
$$

### Minkowski distance ("minkowski")

$$
p = \text{user-provided parameter} \\
dist = \Bigl( \sum{|\vec{x} - \vec{y}| ^ p} \Bigr) ^ \frac{1}{p}
$$

### Hamming distance ("hamming")

$$
dist = \sum{\vec{x} \ne \vec{y}}
$$ 

### The largest difference between values ("maximum")

$$
dist = \max{\vec{x} - \vec{y}}
$$

### Chi-squared divergence ("chisquared")

$$
O_{ij} = \text{augmented matrix from } \vec{x} \text{ and } \vec{y} \\
E_{ij} = \text{matrix of expected count for } O_{ij} \\
dist = \sum{\frac{(O_{ij} - E_{ij}) ^ 2}{ E_{ij}}} \\
$$

### Kullback--Leibler divergence ("kullback")

$$
\vec{p} = \frac{\vec{x}}{\sum{\vec{x}}} \\
\vec{q} = \frac{\vec{y}}{\sum{\vec{y}}} \\
dist = \sum{\vec{q} \log_2{\frac{\vec{q}}{\vec{p}}}}
$$

### Jeffreys divergence ("jeffreys")

$$
\vec{p} = \frac{\vec{x}}{\sum{\vec{x}}} \\
\vec{q} = \frac{\vec{y}}{\sum{\vec{y}}} \\
dist = \sum{\vec{q} \log_2{\frac{\vec{q}}{\vec{p}}}} + 
       \sum{\vec{p} \log_2{\frac{\vec{p}}{\vec{q}}}}
$$

### Jensen-Shannon divergence ("jensen")

$$
\vec{p} = \frac{\vec{x}}{\sum{\vec{x}}} \\
\vec{q} = \frac{\vec{y}}{\sum{\vec{y}}} \\
\vec{m} = \frac{1}{2} (\vec{p} + \vec{q}) \\
dist = \frac{1}{2} \sum{\vec{q} \log_2{\frac{\vec{q}}{\vec{m}}}} + 
       \frac{1}{2} \sum{\vec{p} \log_2{\frac{\vec{p}}{\vec{m}}}}
$$
